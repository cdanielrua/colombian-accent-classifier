# üá®üá¥ Clasificaci√≥n de Acentos Colombianos mediante DSP Artesanal

![Python](https://img.shields.io/badge/Python-3.8%2B-blue?style=for-the-badge&logo=python)
![DSP](https://img.shields.io/badge/Skill-Digital_Signal_Processing-orange?style=for-the-badge)
![Status](https://img.shields.io/badge/Status-Finalizado-success?style=for-the-badge)
![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)

Este proyecto implementa un sistema completo de reconocimiento de patrones de voz para distinguir entre tres acentos colombianos (**Paisas, Rolos y Coste√±os**).

A diferencia de las soluciones modernas basadas en librer√≠as de "caja negra" (como `librosa` o `torchaudio`), este proyecto se destaca por la **implementaci√≥n matem√°tica manual** de cada etapa del procesamiento digital de se√±ales (DSP), desde el filtrado FIR hasta el c√°lculo matricial de la DCT, demostrando un dominio profundo de los fundamentos te√≥ricos del tratamiento de voz.

---

## üß† Fundamento Te√≥rico y Metodolog√≠a

El n√∫cleo del proyecto se basa en la teor√≠a **Fuente-Filtro** de la producci√≥n de voz y en la extracci√≥n de coeficientes **MFCC (Mel Frequency Cepstral Coefficients)**. A continuaci√≥n se detalla la justificaci√≥n de ingenier√≠a para cada etapa:

### 1. Preprocesamiento Riguroso
Para garantizar que el modelo clasifique acentos y no calidades de grabaci√≥n, se estandariz√≥ la se√±al siguiendo estrictos criterios de DSP:

* **Normalizaci√≥n de Amplitud:** Se escala la se√±al al rango `[-1, 1]`. Esto elimina el sesgo del volumen (ganancia del micr√≥fono) en el c√°lculo de distancias vectoriales.
* **Filtro Anti-Aliasing (Pre-Remuestreo):** Se dise√±√≥ e implement√≥ un filtro pasa-bajas FIR con ventana Hamming y frecuencia de corte en **7 kHz**.
    * *Justificaci√≥n:* Al reducir la tasa de muestreo a 16 kHz (Nyquist = 8 kHz), cualquier frecuencia superior a este l√≠mite sufrir√≠a **Aliasing** (solapamiento), "disfraz√°ndose" de frecuencia baja y corrompiendo los formantes vocales. El filtrado previo es obligatorio para preservar la integridad espectral.
* **Remuestreo (Resampling):** Implementado mediante **Interpolaci√≥n Lineal Manual**. Se reduce la se√±al a 16 kHz para disminuir la carga computacional, manteniendo la informaci√≥n relevante de la voz humana (que reside mayoritariamente bajo los 8 kHz).

### 2. Validaci√≥n Estad√≠stica de la Base de Datos
Se verific√≥ mediante pruebas estad√≠sticas que los sujetos de prueba estuvieran pareados por edad entre los diferentes acentos.
* *Importancia:* La voz sufre cambios fisiol√≥gicos con la edad (presbifonia). Asegurar la paridad de edad garantiza que el clasificador aprenda a distinguir **regiones geogr√°ficas** y no grupos etarios (evitando sesgos como "Joven vs Viejo").

### 3. Extracci√≥n de Caracter√≠sticas (Pipeline MFCC)

El proceso de convertir audio en vectores matem√°ticos sigue estos pasos cr√≠ticos:

* **Enventanado (50 ms con solape del 50%):**
    * *Por qu√© 50ms:* Aunque la voz no es estacionaria, el tracto vocal tiene inercia f√≠sica. En intervalos de 50ms, la se√±al se considera **cuasi-estacionaria**, permitiendo un an√°lisis espectral v√°lido.
    * *Por qu√© Hamming:* Multiplicar por una ventana de Hamming suaviza los bordes de la trama a cero, eliminando las discontinuidades temporales que causar√≠an **Fuga Espectral (Spectral Leakage)** en la FFT.
* **Banco de Filtros Mel (26 Filtros):**
    * Se utiliza una escala no lineal que imita la percepci√≥n auditiva humana (mayor resoluci√≥n en bajas frecuencias). Esto permite capturar con precisi√≥n los **Formantes ($F_1, F_2$)**, resonancias que definen las vocales y el timbre del acento.
* **Transformada Discreta del Coseno (DCT):**
    * *Selecci√≥n de 13 Coeficientes:* Al aplicar la DCT y conservar solo los primeros 13 coeficientes ("baja quefrencia"), aislamos la **Envolvente Espectral** (forma del tracto vocal/acento) y descartamos la informaci√≥n de la excitaci√≥n (pitch del individuo).

### 4. Modelado Estad√≠stico (El Vector de Acento)
Cada audio se reduce a un vector √∫nico de 26 dimensiones mediante **Pooling Estad√≠stico**:

| Caracter√≠stica | Representaci√≥n F√≠sica |
| :--- | :--- |
| **Media ($\mu$)** | Representa el **Timbre Est√°tico**. Indica la configuraci√≥n promedio de la boca y la resonancia base del hablante. |
| **Desviaci√≥n Est√°ndar ($\sigma$)** | Representa la **Prosodia y Din√°mica**. Captura el "cantadito" o ritmo del acento (ej. la alta variabilidad tonal del acento paisa vs. la planitud del rolo). |

---

## üìÇ Estructura del Proyecto

```text
‚îú‚îÄ‚îÄ data/                   # Base de datos de audios (Paisas, Rolos, Coste√±os)
‚îú‚îÄ‚îÄ src/                    # C√≥digo fuente
‚îÇ   ‚îú‚îÄ‚îÄ main.py             # Script maestro de ejecuci√≥n y clasificaci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ dsp_utils.py        # Funciones matem√°ticas manuales (FFT, DCT, Filtros)
‚îú‚îÄ‚îÄ images/                 # Gr√°ficas de resultados y diagramas de bloques
‚îú‚îÄ‚îÄ README.md               # Documentaci√≥n del proyecto
‚îî‚îÄ‚îÄ requirements.txt        # Dependencias necesarias
```
---

### üìä Resultados y Eficiencia
El modelo demuestra que no son necesarios algoritmos complejos de Deep Learning para tareas con datasets peque√±os si la Ingenier√≠a de Caracter√≠sticas es robusta.

* **Eficiencia:** El entrenamiento con 30 audios toma menos de 10 segundos en CPU.

* **Interpretabilidad:** El modelo es totalmente explicable ("White Box").

## Desempe√±o:

* **Paisas:** Alta precisi√≥n debido a la detecci√≥n de sibilancia y alta desviaci√≥n est√°ndar (prosodia din√°mica).

* **Rolos vs Coste√±os:** Discriminaci√≥n basada en la aspiraci√≥n de consonantes y la estabilidad voc√°lica.

## üìà Visualizaci√≥n de Distancias
El sistema utiliza la Distancia Coseno para comparar el vector de entrada con los centroides de cada acento.

![alt text](image.png)

### üîÆ Trabajo Futuro
Para escalar este proyecto a un entorno de producci√≥n:

* **Ampliaci√≥n del Dataset:** Recolecci√≥n de muestras en ambientes ruidosos para probar la robustez del filtrado.

* **Clasificadores No Lineales:** Implementaci√≥n de SVM (Support Vector Machines) para encontrar fronteras de decisi√≥n m√°s complejas.

* **Deep Learning:** Uso de CNNs sobre espectrogramas para detectar patrones visuales sutiles si se contara con miles de horas de datos.

## üõ†Ô∏è Instalaci√≥n y Uso
1. Clonar el repositorio:
```bash
git clone https://github.com/cdanielrua/colombian-accent-classifier.git
```

2. Instalar dependencias:
```bash
pip install -r requirements.txt
```

3. Configurar rutas y ejecutar: 
Abre `src/main.py`, ajusta la variable `base_path` a tu carpeta de datos y ejecuta:
```bash
python src/main.py
```
üë®‚Äçüíª Desarrollado por Daniel R√∫a
Desarrollado como proyecto final para la asignatura de Tratamiento de Se√±ales. Ingenier√≠a Electr√≥nica / Telecomunicaciones